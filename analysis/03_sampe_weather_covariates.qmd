# Sample Weather Covariates Through Space-Time Regression Kriging

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import geopandas as gpd
import rasterio
from sklearn.linear_model import LinearRegression
from sklearn.neural_network import MLPRegressor
import sklearn.metrics
import stif

from smhi.conn import get_engine
from smhi.weather import get_weather_data_in_time_range
from sqlalchemy.orm import Session
```

First lets load the random steps we created earlier, it's important that they have been annotated with the geographical covariates as we'll be using some of the in the regression part of this analysis.

```{python}
df = pd.read_csv('../data/localisations/moose_random_steps.csv', index_col=0)
gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['x1_'], df['y1_']), crs=3006)
gdf.head(3)
```

```{python}
gdf = gdf[gdf["case_"] == 1]
gdf = gdf[["step_id_", "x1_", "y1_", "t1_", "season", "season_year"]]
gdf.head(3)
```

# TODO remove when new weather data seeded, then use local date
```{python}
gdf = gdf.rename(columns={
  "x1_": "x",
  "y1_": "y",
  "t1_": "date",
})
gdf["date"] = pd.to_datetime(gdf["date"])
gdf["date"] = 

# gdf["elevation"] = gdf["elevation"].astype(int)

gdf["month"] = gdf["date"].dt.month

  gdf["hour"] = gdf["date"]
  gdf["hour"] -= gdf["hour"].min()
  gdf["hour"] = gdf["hour"].dt.total_seconds() / 3600
  gdf["hour"] = gdf["hour"].astype(int)
  gdf = gdf.sort_values(by=['hour'])
  
```

```{python}
# For weather covariates its important we base them on the start of the step only, as that's why the animals decision is made
# If you wanted to see if animals could predict weather, end step could be a fun experiment!
gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['x1_'], df['y1_']), crs=3006)
```

```{python}
gdf.columns
```

```{python}
# TODO remove with updated weather data variables
gdf = gdf[gdf["case_"] == 1,] # only need to calculate begin steps, so the real step start
gdf = gdf[["x1_", "y1_", "step_id_"]] # elevation
```

```{python}
def get_season_dates(season, year):
  """
  Given a season name (winter/summer) and year, return the start and end dates
  for that season (December to March for Winter, June to August for Summer).
  """
  if season == "winter":
      season_start = pd.Timestamp(f"{year}-12-01").tz_localize('Europe/Stockholm')
      season_end = pd.Timestamp(f"{year + 1}-03-31").tz_localize('Europe/Stockholm')
  elif season == "summer":
      season_start = pd.Timestamp(f"{year}-06-01").tz_localize('Europe/Stockholm')
      season_end = pd.Timestamp(f"{year}-08-31").tz_localize('Europe/Stockholm')
  
  return season_start, season_end

def get_seasonal_weather_data(season, year):
  smhi_engine = get_engine()
  with Session(engine) as Session:
    df = get_weather_data_in_time_range(
      session, 
      time_range=[start_date, end_date], 
      parameter="air_temperature"
    ) 
    df = df.drop_duplicates(subset=["x", "y", "date"])
```

```{python}
def remove_clustered_space_time_coords(gdf):
  # Convert timestamps to a numerical scale 
  gdf['timestamp_numeric'] = gdf['date'].astype(int) / 1e9 # Convert to seconds 
  # Combine spatial and temporal features 
  coords_time = np.column_stack((gdf.geometry.x, gdf.geometry.y, gdf['timestamp_numeric'])) 
  # Fit DBSCAN (adjust eps values for space/time) 
  clustering = DBSCAN(eps=100, min_samples=2, metric='euclidean').fit(coords_time) 
  gdf = gdf[clustering.labels_ == -1] 
  gdf = gdf.drop(columns=["timestamp_numeric"]) 

  return gdf
```

```{python}
def create_variogram():
  variogram_params = {
    "space_dist_max": 8e5,
    "time_dist_max": 10,
    "el_max": 1e8
  } 
  predictor.calc_empirical_variogram(**variogram_params)
  predictor.plot_empirical_variogram()
  predictor.plot_variogram_model_comparison()

def create_space_time_kriging_model(gdf):
  covariate_colnames = ["elevation"]
  data = stif.Data(
    gdf,
    space_cols=["x", "y"],
    time_col="hour",
    predictand_col="value",
    covariate_cols=covariate_colnames,
  )

  # Create Linear Regression Model
  covariate_model = LinearRegression()
  predictor = stfi.Predictor(data, covariate_model)

  predictor.calc_cross_validation(cv_split=ShuffledKFold)
  score = predictor.get_cross_val_metric(sklearn.metrics.explained_variance_score)
  print("Explained variance by linear regression model: ", score)
  predictor.plot_cross_validation_residuals()

def fit_kriging_model():
  kriging_params = {
    "min_kriging_points": 1,
    "max_kriging_points": 10,
    "space_dist_max": 3e5,
    "time_dist_max": 3
  }
  cross_validate(predictor, kriging_params, variogram_params)
```

```{python}

from datetime import datetime import pandas as pd import matplotlib.pyplot as plt import geopandas as gpd from sklearn.linear_model import LinearRegression import sklearn.metrics import rioxarray as rxr

from sqlalchemy.orm import Session from stif import Data from stif import Predictor from sklearn.cluster import DBSCAN import numpy as np

from database.animal.models import Localisation from database.base import get_engine from database.weather.functions import get_weather_data

class ShuffledKFold(sklearn.model_selection.KFold): def init(self, n_splits): super().__init__(n_splits, shuffle=True)

def cross_validate(predictor, kriging_params, variogram_params): # Create kriging cross validation predictor.calc_cross_validation( kriging=True, verbose=True, geostat_params={ "variogram_params": variogram_params, "kriging_params": kriging_params, }, cv_split=ShuffledKFold ) predictor.plot_cross_validation_residuals() print(predictor.get_cross_val_metric(sklearn.metrics.mean_absolute_error))

def get_kriging_data(engine, show_plots=True, cross_validate=False): with Session(engine) as session: gdf = get_seasonal_weather_data(session) gdf = remove_clustered_space_time_coords(gdf)

# gdf = pd.get_dummies(gdf, drop_first=True) # for landuse classes
covariate_colnames = [col for col in list(gdf.columns.values) if col not in ("geometry", "hour", "date", "value", "landuse")]
data = stif.Data(
  gdf,
  space_cols=["x", "y"],
  time_col="hour",
  predictand_col="value",
  covariate_cols=covariate_colnames,
)



# Create space-time variogram
variogram_params = {
  "space_dist_max": 8e5,
  "time_dist_max": 10,
  "el_max": 1e8
} 
predictor.calc_empirical_variogram(**variogram_params)

if show_plots:
  predictor.plot_empirical_variogram()
  predictor.plot_variogram_model_comparison()

# FULL FITTING OF MODEL
kriging_params = {
  "min_kriging_points": 1,
  "max_kriging_points": 10,
  "space_dist_max": 3e5,
  "time_dist_max": 3
}
if cross_validate:
  cross_validate(predictor, kriging_params, variogram_params)

# PREDICT
predictor.fit_variogram_model(st_model='sum_metric')

dem = rxr.open_rasterio("data/geography/elevation/elevation.tif")
dem = dem.sel(band=1).where(dem != 0)
dem.name = "elevation"
dem_coarse = dem.coarsen(x=100, y=100, boundary="trim").mean(skipna=True)
pred_grid = dem_coarse.to_dataframe().reset_index()[["x", "y", "elevation"]]

prediction_df = pd.DataFrame({"x": pred_grid["x"], "y": pred_grid["y"], "elevation": pred_grid["elevation"], "hour": 800})
prediction_df = prediction_df.dropna()
prediction_df["elevation"] = prediction_df["elevation"].astype(int)

prediction_gdf = gpd.GeoDataFrame(
  prediction_df,
  geometry=gpd.points_from_xy(prediction_df['x'], prediction_df['y'])
)

prediction_gdf.set_crs(epsg=3006, inplace=True)

# PREDICT KRIGING
res_mean, res_std = predictor.predict(prediction_gdf, kriging_params)
prediction_gdf["prediction_mean"] = res_mean
prediction_gdf["prediction_std"] = res_std

fig, axs = plt.subplots(1, 2, figsize=(10, 5))
ax = axs[0]
prediction_gdf.plot(column="prediction_mean", cmap="viridis", legend=True, ax=ax, markersize=9, marker="s")
ax.set_title("Prediction mean")
ax.set_xlabel("longitude")
ax.set_ylabel("latitude")

ax = axs[1]
prediction_gdf.plot(column="prediction_std", cmap="magma", legend=True, ax=ax, markersize=9, marker="s")
ax.set_title("Prediction standard deviation")
ax.set_xlabel("longitude")
ax.set_ylabel("latitude")
fig.tight_layout()
breakpoint()
pass


```